{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship Strength Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "#Update float display to avoid timestamps showing in scientific notation\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "#import the two files. data_export is the emails/manual scoring, Relationship_Strength_Training \n",
    "email_data=pd.read_csv(\"data_export\", header=None)\n",
    "relationship_data=pd.read_csv(\"Relationship_Strength_Training.csv\", header=0)\n",
    "\n",
    "#give unnamed columns names\n",
    "email_data.rename(columns={0:'date', 1:'email_address', 2:'email_subject', 3:'email_text', \n",
    "                           4:'professionalism', 5:'feeling', 6:'weight'}, inplace=True)\n",
    "\n",
    "#drop columns leftover from the list of people inputting names\n",
    "relationship_data.drop([\"Unnamed: 5\", \"Unnamed: 6\", \"Person\", \"Relationships scored\"], axis=1, inplace=True)\n",
    "\n",
    "#make email adresses all lowercase to avoid mismatches based on case\n",
    "email_data['email_address'] = email_data['email_address'].str.lower()\n",
    "relationship_data['Email Address'] = relationship_data['Email Address'].str.lower()\n",
    "\n",
    "#merge the two data sets into one by matching email addresses\n",
    "full_relationship_data = email_data.merge(relationship_data, left_on='email_address', right_on='Email Address', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(758, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are only 4 rows with nan values (due to email address mismatching on merging, so it seems reasonable to drop them)\n",
    "full_relationship_data = full_relationship_data.dropna()\n",
    "full_relationship_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this section, we want to use the timestamps to decide if the emails were sent on a weekday or weekend \n",
    "for adding to the model for predicting professionalism. This is going to be noisy data because the time zones weren't recorded\n",
    "\"\"\"\n",
    "full_relationship_data['date'] = full_relationship_data['date'].apply(lambda x: datetime.datetime.utcfromtimestamp(x))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converts utc to day of the week as a number 1-7\n",
    "full_relationship_data['day_of_week'] = full_relationship_data['date'].apply(lambda x: datetime.datetime.weekday(x))\n",
    "#creates a binary variable to determine if the email was sent on a weekday\n",
    "full_relationship_data['weekday_bin'] = full_relationship_data['day_of_week'].apply(lambda x: True if x in range(2,7) else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"In this section, we're going to pull salutations out of the emails using code from: \n",
    "https://github.com/Trindaz/EFZP. Classify formality by pulling out list of values and manually building classifier.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"This section will use sent_tekenize in nltk.tokenize to tokenize the sentences.\n",
    "This will be used to build a variable for number of sentences and average sentence length in each email.\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Lemmatize the words using the lemmatizer in nltk. This will hopefully allow us to more acurately\n",
    "compare emails by reducing the number of unique words. OTOH it may remove difference in conotation \n",
    "in relation to professionalism/feeling so we'll want to consider the model with/without lemmatization\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Sentiment analysis.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Exploration of the resulting data\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
